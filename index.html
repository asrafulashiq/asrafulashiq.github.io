<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Ashraful Islam" />

  
  
  
    
  
  <meta name="description" content="Graduate Research Assistant" />

  
  <link rel="alternate" hreflang="en-us" href="https://asrafulashiq.github.io/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#ff3860" />
  

  
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.425f6090681376e852d994fa57e4d96e.css" />

  



  

  

  




  
  
  
    <script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>
  

  
    <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Ashraful" />
  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_2.png" />

  <link rel="canonical" href="https://asrafulashiq.github.io/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Ashraful" />
  <meta property="og:url" content="https://asrafulashiq.github.io/" />
  <meta property="og:title" content="Ashraful" />
  <meta property="og:description" content="Graduate Research Assistant" /><meta property="og:image" content="https://asrafulashiq.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png" />
    <meta property="twitter:image" content="https://asrafulashiq.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="og:updated_time" content="2021-07-20T00:00:00&#43;00:00" />
    
  

  

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://asrafulashiq.github.io/?q={search_term_string}",
    "query-input": "required name=search_term_string"
  },
  "url": "https://asrafulashiq.github.io/"
}
</script>


  

  

  





  <title>Ashraful</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class="page-wrapper   "  >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.226a9011996d125bf3fe4a5f22353a49.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about" data-target="#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#experience" data-target="#experience"><span>Experience</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications" data-target="#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#news" data-target="#news"><span>News</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact" data-target="#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
            
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="https://drive.google.com/file/d/1ly0pWsLP7MAj1-9eiiIMWqErK4odFdNV/view?usp=sharing" target="_blank" rel="noopener"><span>CV</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    











  
<span class="js-widget-page d-none"></span>





  
  
  
  




  
  
  
  

  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="about" class="home-section wg-about  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    

      




  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-circle" src="/authors/admin/avatar_hu7b0dbd06dd1676b7ee1b6295bec7b98b_168986_270x270_fill_q75_lanczos_center.jpeg" alt="Ashraful Islam">
      

      <div class="portrait-title">
        <h2>Ashraful Islam</h2>
        <h3>Graduate Research Assistant</h3>

        
        <h3>
          <a href="https://www.rpi.edu/" target="_blank" rel="noopener">
          <span>Rensselaer Polytechnic Institute</span>
          </a>
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.com/citations?user=QC0yhKoAAAAJ&amp;hl=en" target="_blank" rel="noopener" aria-label="graduation-cap">
            <i class="fas fa-graduation-cap big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://github.com/asrafulashiq" target="_blank" rel="noopener" aria-label="github">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://www.linkedin.com/in/ashraful-islam-04340397/" target="_blank" rel="noopener" aria-label="linkedin">
            <i class="fab fa-linkedin big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    <h1>Ashraful Islam</h1>

    <div class="article-style">
      <p>Hello!
I am a fourth year PhD student at the ECSE department of <a href="https://www.ecse.rpi.edu/" target="_blank" rel="noopener">Rensselaer Polytechnic Institute (RPI)</a>, Troy, NY, supervised by <a href="https://www.ecse.rpi.edu/~rjradke/index.htm" target="_blank" rel="noopener">Prof. Richard Radke</a>. Broadly, I am interested in computer vision and deep learning. I develop neural network models for unsupervised, semi-supervised, weakly-supervised, and few-shot learning. I have also worked on action detection and object tracking.</p>
<p>Previously, I spent three wonderful summers at  <a href="https://www.microsoft.com/en-us/research/" target="_blank" rel="noopener">Microsoft Research</a>, <a href="https://www.research.ibm.com/labs/watson/https://www.research.ibm.com/labs/watson/" target="_blank" rel="noopener">IBM Research</a> and <a href="https://www.kitware.com/" target="_blank" rel="noopener">Kitware</a>. I completed my undergrad in Electrical Engineering from <a href="https://eee.buet.ac.bd/" target="_blank" rel="noopener">BUET</a>, Bangladesh.</p>
<p>
  <i class="fas fa-download  pr-1 fa-fw"></i>  My <a href="https://drive.google.com/open?id=1ly0pWsLP7MAj1-9eiiIMWqErK4odFdNV" target="_blank" rel="noopener">Resumé</a>.</p>

    </div>

    <div class="row">

      
      <div class="col-md-5">
        <div class="section-subheading">Interests</div>
        <ul class="ul-interests">
          
          <li>Computer Vision</li>
          
          <li>Deep Learning</li>
          
          <li>Self-supervised Learning</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <div class="section-subheading">Education</div>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">PhD in Computer Engineering, 2021(Expected)</p>
              <p class="institution">Rensselaer Polytechnic Institute (RPI)</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MS in Computer Engineering, 2019</p>
              <p class="institution">Rensselaer Polytechnic Institute (RPI)</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">BS in EE, 2017</p>
              <p class="institution">Bangladesh University of Engineering and Technology (BUET)</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>


    

    </div>
  </section>

  
  
  
  

  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="experience" class="home-section wg-experience  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    
      <div class="row  ">
      
        
          <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class="mb-0">Experience</h1>
            
          </div>
        
      
    

      




<div class="col-12 col-lg-8">
  

  
  
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col ">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border ">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">
          <div class="section-subheading card-title exp-title text-muted mt-0 mb-1">Research Intern</div>
          <div class="section-subheading card-title exp-company text-muted my-0"><a href="https://www.microsoft.com/en-us/research/" target="_blank" rel="noopener">Microsoft Research</a></div>
          <div class="text-muted exp-meta">
            May 2021 –
            
              Aug 2021
            
            
              <span class="middot-divider"></span>
              <span>WA</span>
            
          </div>
          <div class="card-text">My work focuses broadly on self­-supervised multi­task representation learning for 3D computer vision. Specifically, I am working on self-supervised pretraining of deep neural networks that provide better representations for downstream camera pose estimation and segmentation task.</div>
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border ">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">
          <div class="section-subheading card-title exp-title text-muted mt-0 mb-1">Research Intern</div>
          <div class="section-subheading card-title exp-company text-muted my-0"><a href="https://www.research.ibm.com/labs/watson/" target="_blank" rel="noopener">IBM Research</a></div>
          <div class="text-muted exp-meta">
            Jun 2020 –
            
              Aug 2020
            
            
              <span class="middot-divider"></span>
              <span>NY</span>
            
          </div>
          <div class="card-text">I researched on unsupervised and supervised contrastive representation learning for transfer learning. Our study suggests that networks trained with contrastive loss is more transferable to a different domain than the networks trained with supervised cross-entropy loss. Proposed and analyzed joint objective of self-supervised contrastive loss with cross-entropy or supervised contrastive loss that leads to better transferability of these models over their standard-trained counterparts.</div>
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border ">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">
          <div class="section-subheading card-title exp-title text-muted mt-0 mb-1">Research Intern</div>
          <div class="section-subheading card-title exp-company text-muted my-0"><a href="https://www.kitware.com/" target="_blank" rel="noopener">Kitware Inc.</a></div>
          <div class="text-muted exp-meta">
            May 2019 –
            
              Aug 2019
            
            
              <span class="middot-divider"></span>
              <span>NY</span>
            
          </div>
          <div class="card-text">I developed a deep adversarial model titled &lsquo;Dual-order Attentive Generative Adversarial Network (DOA-GAN)&rsquo; for image and video copy-move forgery detection and localization.</div>
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border exp-fill">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col ">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">
          <div class="section-subheading card-title exp-title text-muted mt-0 mb-1">Graduate Research Assistant</div>
          <div class="section-subheading card-title exp-company text-muted my-0"><a href="https://www.rpi.edu/" target="_blank" rel="noopener">Rensselaer Polytechnic Institute</a></div>
          <div class="text-muted exp-meta">
            Aug 2017 –
            
              Present
            
            
              <span class="middot-divider"></span>
              <span>NY</span>
            
          </div>
          <div class="card-text"><ul>
<li>Developed a framework for cross-domain few-shot learning that uses unlabeled images from novel dataset during meta-training.</li>
<li>Proposed a weakly supervised temporal action localization method using metric learning that only requires video-level action instances as supervision during training. Also developed a deep learning model with <em>hybrid attention mechanism (HAMNet)</em> for solving the issues of action completeness and background modeling in temporal action localization with weak supervision, outperforming SOTA methods by atleast 2.8%.</li>
<li>Developed a system that automatically tracks passengers and items, and detects unusual activities (baggage theft, left-behind items, etc.) at an airport security checkpoint (demo <a href="https://drive.google.com/file/d/1KNUabcVEKMsFvQQ1u_NB5ZI6J9kRHuEe/view?usp=sharing">video</a>).</li>
</ul>
</div>
        </div>
      </div>
    </div>
  </div>
  
  
</div>


    
      </div>
    

    </div>
  </section>

  
  
  
  

  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="publications" class="home-section wg-pages  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    
      <div class="row  ">
      
        
          <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class="mb-0">Publications</h1>
            
          </div>
        
      
    

      








  













  












  





  




<div class="col-12 col-lg-8">

  

  
    
      







  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      A Islam</span>, <span >
      R Chen</span>, <span >
      R Panda</span>, <span >
      L Karlinksky</span>, <span >
      RJ Radke</span>, <span >
      RS Feris</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Jul 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      ICCV
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

  

  
  
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/broad_tfm/">A Broad Study on the Transferability of Visual Representations with Contrastive Learning</a>
  </div>

  
  <a href="/publication/broad_tfm/" class="summary-link">
    <div class="article-style">
      <p>We conduct a comprehensive study on the transferability of learned representations of different contrastive approaches for linear evaluation, full-network transfer, and few-shot recognition on 12 downstream datasets from different domains, and object detection tasks on MSCOCO and VOC0712. The results show that the contrastive approaches learn representations that are easily transferable to a different downstream task. We further observe that the joint objective of self-supervised contrastive loss with cross-entropy/supervised-contrastive loss leads to better transferability of these models over their supervised counterparts.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2103.13517" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/broad_tfm/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/asrafulashiq/transfer_broad" target="_blank" rel="noopener">
  Code
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=E2poAVwhxWc&amp;list=PLFFnmJXKA-xz6DRF3ZaftkRZS8bOaYzHR&amp;index=2" target="_blank" rel="noopener">
  Video
</a>





  </div>
  

</div>

    
  
    
      







  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      A Islam</span>, <span >
      R Chen</span>, <span >
      R Panda</span>, <span >
      L Karlinksky</span>, <span >
      RS Feris</span>, <span >
      RJ Radke</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Jun 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      arXiv
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

  

  
  
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/dynamic/">Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data</a>
  </div>

  
  <a href="/publication/dynamic/" class="summary-link">
    <div class="article-style">
      <p>We propose a simple dynamic distillation-based approach to facilitate unlabeled images from the novel/base dataset. We impose consistency regularization by calculating predictions from the weakly-augmented versions of the unlabeled images from a teacher network and matching it with the strongly augmented versions of the same images from a student network. The parameters of the teacher network are updated as exponential moving average of the parameters of the student network. We show that the proposed network learns representation that can be easily adapted to the target domain even though it has not been trained with target-specific classes during the pretraining phase.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2106.07807" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/dynamic/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/asrafulashiq/dynamic-cdfsl" target="_blank" rel="noopener">
  Code
</a>














  </div>
  

</div>

    
  
    
      







  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      A Islam</span>, <span >
      R Chen</span>, <span >
      R Panda</span>, <span >
      L Karlinksky</span>, <span >
      RJ Radke</span>, <span >
      RS Feris</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Apr 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      CVPRW
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

  

  
  
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/fs_cvprw/">A Simple Framework for Cross-Domain Few-Shot Recognition with Unlabeled Data</a>
  </div>

  
  <a href="/publication/fs_cvprw/" class="summary-link">
    <div class="article-style">
      <p>We tackle the problem of cross-domain few-shot learning where there is a large shift between the base and target domain. We propose a simple solution to utilize unlabeled images from the novel/base dataset by calculating pseudo soft-label from the weakly-augmented version of the unlabeled image and compare it with the strongly augmented version. Our model outperforms the current state-of-the art method by 2.7% for 5-shot and 3.6% for 1-shot classification in the BSCD-FSL benchmark.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/fs_cvprw/fs_cvprw.pdf" target="_blank" rel="noopener">
  PDF
</a>









  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/1kz95vpx1wVK_p_klLnWtMzD73wHy8mBj/view?usp=sharing" target="_blank" rel="noopener">
  Poster
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/123yODqcmkLHcTso27pefXGadG4mcr7K2/view?usp=sharing" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://youtu.be/2tyWXZruVx8" target="_blank" rel="noopener">
  Video
</a>





  </div>
  

</div>

    
  
    
      







  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      A Islam</span>, <span >
      C Long</span>, <span >
      RJ Radke</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Feb 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      AAAI
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

  

  
  
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/hamnet/">A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization </a>
  </div>

  
  <a href="/publication/hamnet/" class="summary-link">
    <div class="article-style">
      <p>Most existing methods in weakly-supervised action localization rely on a Multiple Instance Learning (MIL) framework to predict the start and end frame of each action category in a video. However, the existing MIL-based approach has a major limitation of only capturing the most discriminative frames of an action, ignoring the full extent of an activity. Moreover, these methods cannot model background activity effectively, which plays an important role in localizing foreground activities. In this paper, we present a novel framework named HAM-Net with a hybrid attention mechanism which includes temporal soft, semi-soft and hard attentions to address these issues.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2101.00545" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/hamnet/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/asrafulashiq/hamnet" target="_blank" rel="noopener">
  Code
</a>






  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/10N321SH8A7lsm3cYVzZe37Mlq4mRlUdM/view?usp=sharing" target="_blank" rel="noopener">
  Poster
</a>









  </div>
  

</div>

    
  
    
      







  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      A Islam</span>, <span >
      C Long</span>, <span >
      A Basharat</span>, <span >
      A Hoogs</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Jun 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      CVPR
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

  

  
  
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/doagan/">DOA-GAN: Dual-Order Attentive Generative Adversarial Network for Image Copy-move Forgery Detection and Localization</a>
  </div>

  
  <a href="/publication/doagan/" class="summary-link">
    <div class="article-style">
      <p>We propose a Generative Adversarial Network with a dual-order attention model to detect and localize copy-move forgeries. In the generator, the firstorder attention is designed to capture copy-move location information, and the second-order attention exploits more discriminative features for the patch co-occurrence.  The discriminator network is designed to further ensure more accurate localization results.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Islam_DOA-GAN_Dual-Order_Attentive_Generative_Adversarial_Network_for_Image_Copy-Move_Forgery_CVPR_2020_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/doagan/cite.bib">
  Cite
</a>







  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/open?id=1iiSL9XbH6CqO2Ftq-YlMFMQJ12dzib2V" target="_blank" rel="noopener">
  Poster
</a>





  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/open?id=1dmR9o31IPV2wqSdnUDsP42KjslFCua46" target="_blank" rel="noopener">
  Video
</a>





  </div>
  

</div>

    
  
    
      







  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      A Islam</span>, <span >
      RJ Radke</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Mar 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      WACV
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

  

  
  
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/dml/">Weakly Supervised Temporal Action Localization Using Deep Metric Learning</a>
  </div>

  
  <a href="/publication/dml/" class="summary-link">
    <div class="article-style">
      <p>It is expensive and time-consuming to annotate both action labels and temporal boundaries of videos. We propose a weakly supervised temporal action localization method that only requires video-level action instances as supervision during training.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://openaccess.thecvf.com/content_WACV_2020/papers/Islam_Weakly_Supervised_Temporal_Action_Localization_Using_Deep_Metric_Learning_WACV_2020_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/dml/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/asrafulashiq/wsad" target="_blank" rel="noopener">
  Code
</a>






  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/open?id=1Yn7wFNRQIXKzuU48AwaWRwMcjw_jaVeX" target="_blank" rel="noopener">
  Poster
</a>





  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/open?id=1aJAj3cQr4F9wsasyoQd9dcJualgMDRfP" target="_blank" rel="noopener">
  Video
</a>





  </div>
  

</div>

    
  
    
      







  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      A Islam</span>, <span >
      Y Zhang</span>, <span >
      D Yin</span>, <span >
      O Camps</span>, <span >
      RJ Radke</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Sep 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      ICDSC
    
  </span>
  

  

  
  
  
  
  
  

  
  

</div>

  

  
  
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/corr/">Correlating Belongings with Passengers in a Simulated Airport Security Checkpoint</a>
  </div>

  
  <a href="/publication/corr/" class="summary-link">
    <div class="article-style">
      <p>Automatic algorithms for tracking and associating passengers and their divested objects at an airport security screening checkpoint would have great potential for improving checkpoint efficiency, including flow analysis, theft detection, line-of-sight maintenance, and risk-based screening. In this paper, we present algorithms for these tracking and association problems and demonstrate their effectiveness in a full-scale physical simulation of an airport security screening checkpoint.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.ecse.rpi.edu/~rjradke/papers/islam-icdsc18.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/corr/cite.bib">
  Cite
</a>











  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/1KNUabcVEKMsFvQQ1u_NB5ZI6J9kRHuEe/view?usp=sharing" target="_blank" rel="noopener">
  Video
</a>





  </div>
  

</div>

    
  

  
  
  

</div>


    
      </div>
    

    </div>
  </section>

  
  
  
  

  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="news" class="home-section wg-blank  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    
      <div class="row  ">
      
        
          <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class="mb-0">Recent News</h1>
            
          </div>
        
      
    

      



  <div class="col-12 col-lg-8">
    <ul>
<li><strong>Sep 2021</strong>: One <a href="https://arxiv.org/abs/2106.07807" target="_blank" rel="noopener">paper</a> accepted to <strong><a href="https://nips.cc/Conferences/2021/" target="_blank" rel="noopener">NeurIPS 2021</a></strong>.</li>
<li><strong>July 2021</strong>: Our <a href="https://arxiv.org/abs/2103.13517" target="_blank" rel="noopener">paper</a> on contrastive learning accepted to <strong><a href="http://iccv2021.thecvf.com/home" target="_blank" rel="noopener">ICCV 2021</a></strong>.</li>
<li><strong>May 2021</strong>: Started summer internship at <a href="https://www.microsoft.com/en-us/research/" target="_blank" rel="noopener">Microsoft Research</a>.</li>
<li><strong>April 2020</strong>: Passed Doctoral Candidacy Exam.</li>
<li><strong>April 2020</strong>: Paper accepted as <strong>oral</strong> to <strong><a href="https://l2id.github.io/" target="_blank" rel="noopener">CVPR L2ID workshop</a></strong>.</li>
<li><strong>Dec 2020</strong>: Paper accepted to <strong>AAAI 2021</strong>.</li>
<li><strong>June 2020</strong>: Started summer internship at <a href="https://www.research.ibm.com/labs/watson/" target="_blank" rel="noopener">IBM Research</a>.</li>
<li><strong>Feb 2020</strong>: Paper accepted to <strong>CVPR 2020</strong>.</li>
<li><strong>Dec 2019</strong>: Paper accepted to <strong>WACV 2020</strong>.</li>
<li><strong>May 2019</strong>: Started summer internship at <a href="https://www.kitware.com/" target="_blank" rel="noopener">Kitware Inc</a>.</li>
<li><strong>Sep 2018</strong>: Best paper award in <strong>ICDSC 2018</strong>.</li>
</ul>

  </div>



    
      </div>
    

    </div>
  </section>

  
  
  
  

  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  
  

  
  <section id="contact" class="home-section wg-contact  "  >
   <div class="home-section-bg " ></div>
    <div class="container">

    
      <div class="row  ">
      
        
          <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class="mb-0">Contact</h1>
            
          </div>
        
      
    

      















<div class="col-12 col-lg-8">
  

  

  <ul class="fa-ul">

    
    <li>
      <i class="fa-li fas fa-envelope fa-2x" aria-hidden="true"></i>
      <span id="person-email"><a href="mailto:asrafulashiq@gmail.com">asrafulashiq@gmail.com</a></span>
    </li>
    

    
    <li>
      <i class="fa-li fas fa-phone fa-2x" aria-hidden="true"></i>
      <span id="person-telephone"><a href="tel:%28347%29%20536-0812">(347) 536-0812</a></span>
    </li>
    

    
    
      
      <li>
        <i class="fa-li fas fa-map-marker fa-2x" aria-hidden="true"></i>
        <span id="person-address">1508 15th St, Troy, NY 12180</span>
      </li>
    

    

    

    

    
    

  </ul>

  

</div>


    
      </div>
    

    </div>
  </section>



  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
      

    

    
    
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.b61a8f62b6e5c0cd322c8158c5b5dfb6.js"></script>

    






</body>
</html>
